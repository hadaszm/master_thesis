{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import river\n",
    "import river.datasets as datasets\n",
    "from river import stream\n",
    "from pprint import pprint\n",
    "import os\n",
    "from scipy.io import arff\n",
    "import pandas as pd\n",
    "from river import tree\n",
    "from river import evaluate\n",
    "from river import metrics\n",
    "\n",
    "import numpy as np\n",
    "from  streams.stream_section import StreamSection\n",
    "from streams.utils import FL, FU, generate_stream_section\n",
    "from my_datasets.getting_datasets import get_LED,get_Hyperplane,get_Electricity,get_AGRAWL,get_Airlines,get_CoverType,get_RandomRBF\n",
    "from train_and_eval import train_and_evaluate\n",
    "from functools import partial\n",
    "from train_and_eval import train_and_evaluate\n",
    "from river.metrics.accuracy import Accuracy\n",
    "from multiprocessing.pool import ThreadPool\n",
    "from river.datasets.synth import ConceptDriftStream\n",
    "from tqdm import tqdm\n",
    "\n",
    "# methods\n",
    "from river.dummy import NoChangeClassifier,PriorClassifier\n",
    "from river.cluster import CluStream\n",
    "from river.forest.adaptive_random_forest import ARFClassifier\n",
    "from river.tree.hoeffding_adaptive_tree_classifier import  HoeffdingAdaptiveTreeClassifier\n",
    "from river.neighbors import KNNClassifier as riverKNN\n",
    "from river.naive_bayes import GaussianNB\n",
    "from semisupervised_methods.clustream_and_label import CluserAndLabel\n",
    "from semisupervised_methods.incremental_classifier import IncrementalClassifer\n",
    "from semisupervised_methods.one_nearest_neighbour import oneNNClassifer\n",
    "from river.drift import ADWIN, PageHinkley\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Elevation</th>\n",
       "      <th>Aspect</th>\n",
       "      <th>Slope</th>\n",
       "      <th>Horizontal_Distance_To_Hydrology</th>\n",
       "      <th>Vertical_Distance_To_Hydrology</th>\n",
       "      <th>Horizontal_Distance_To_Roadways</th>\n",
       "      <th>Hillshade_9am</th>\n",
       "      <th>Hillshade_Noon</th>\n",
       "      <th>Hillshade_3pm</th>\n",
       "      <th>Horizontal_Distance_To_Fire_Points</th>\n",
       "      <th>...</th>\n",
       "      <th>Soil_Type_30</th>\n",
       "      <th>Soil_Type_31</th>\n",
       "      <th>Soil_Type_32</th>\n",
       "      <th>Soil_Type_33</th>\n",
       "      <th>Soil_Type_34</th>\n",
       "      <th>Soil_Type_35</th>\n",
       "      <th>Soil_Type_36</th>\n",
       "      <th>Soil_Type_37</th>\n",
       "      <th>Soil_Type_38</th>\n",
       "      <th>Soil_Type_39</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2596.0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>258.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>510.0</td>\n",
       "      <td>221.0</td>\n",
       "      <td>232.0</td>\n",
       "      <td>148.0</td>\n",
       "      <td>6279.0</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2590.0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>212.0</td>\n",
       "      <td>-6.0</td>\n",
       "      <td>390.0</td>\n",
       "      <td>220.0</td>\n",
       "      <td>235.0</td>\n",
       "      <td>151.0</td>\n",
       "      <td>6225.0</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2804.0</td>\n",
       "      <td>139.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>268.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>3180.0</td>\n",
       "      <td>234.0</td>\n",
       "      <td>238.0</td>\n",
       "      <td>135.0</td>\n",
       "      <td>6121.0</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2785.0</td>\n",
       "      <td>155.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>242.0</td>\n",
       "      <td>118.0</td>\n",
       "      <td>3090.0</td>\n",
       "      <td>238.0</td>\n",
       "      <td>238.0</td>\n",
       "      <td>122.0</td>\n",
       "      <td>6211.0</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2595.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>153.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>391.0</td>\n",
       "      <td>220.0</td>\n",
       "      <td>234.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>6172.0</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>581007</th>\n",
       "      <td>2396.0</td>\n",
       "      <td>153.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>85.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>108.0</td>\n",
       "      <td>240.0</td>\n",
       "      <td>237.0</td>\n",
       "      <td>118.0</td>\n",
       "      <td>837.0</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>581008</th>\n",
       "      <td>2391.0</td>\n",
       "      <td>152.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>95.0</td>\n",
       "      <td>240.0</td>\n",
       "      <td>237.0</td>\n",
       "      <td>119.0</td>\n",
       "      <td>845.0</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>581009</th>\n",
       "      <td>2386.0</td>\n",
       "      <td>159.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>236.0</td>\n",
       "      <td>241.0</td>\n",
       "      <td>130.0</td>\n",
       "      <td>854.0</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>581010</th>\n",
       "      <td>2384.0</td>\n",
       "      <td>170.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>230.0</td>\n",
       "      <td>245.0</td>\n",
       "      <td>143.0</td>\n",
       "      <td>864.0</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>581011</th>\n",
       "      <td>2383.0</td>\n",
       "      <td>165.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>231.0</td>\n",
       "      <td>244.0</td>\n",
       "      <td>141.0</td>\n",
       "      <td>875.0</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>581012 rows × 54 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Elevation  Aspect  Slope  Horizontal_Distance_To_Hydrology  \\\n",
       "0          2596.0    51.0    3.0                             258.0   \n",
       "1          2590.0    56.0    2.0                             212.0   \n",
       "2          2804.0   139.0    9.0                             268.0   \n",
       "3          2785.0   155.0   18.0                             242.0   \n",
       "4          2595.0    45.0    2.0                             153.0   \n",
       "...           ...     ...    ...                               ...   \n",
       "581007     2396.0   153.0   20.0                              85.0   \n",
       "581008     2391.0   152.0   19.0                              67.0   \n",
       "581009     2386.0   159.0   17.0                              60.0   \n",
       "581010     2384.0   170.0   15.0                              60.0   \n",
       "581011     2383.0   165.0   13.0                              60.0   \n",
       "\n",
       "        Vertical_Distance_To_Hydrology  Horizontal_Distance_To_Roadways  \\\n",
       "0                                  0.0                            510.0   \n",
       "1                                 -6.0                            390.0   \n",
       "2                                 65.0                           3180.0   \n",
       "3                                118.0                           3090.0   \n",
       "4                                 -1.0                            391.0   \n",
       "...                                ...                              ...   \n",
       "581007                            17.0                            108.0   \n",
       "581008                            12.0                             95.0   \n",
       "581009                             7.0                             90.0   \n",
       "581010                             5.0                             90.0   \n",
       "581011                             4.0                             67.0   \n",
       "\n",
       "        Hillshade_9am  Hillshade_Noon  Hillshade_3pm  \\\n",
       "0               221.0           232.0          148.0   \n",
       "1               220.0           235.0          151.0   \n",
       "2               234.0           238.0          135.0   \n",
       "3               238.0           238.0          122.0   \n",
       "4               220.0           234.0          150.0   \n",
       "...               ...             ...            ...   \n",
       "581007          240.0           237.0          118.0   \n",
       "581008          240.0           237.0          119.0   \n",
       "581009          236.0           241.0          130.0   \n",
       "581010          230.0           245.0          143.0   \n",
       "581011          231.0           244.0          141.0   \n",
       "\n",
       "        Horizontal_Distance_To_Fire_Points  ...  Soil_Type_30  Soil_Type_31  \\\n",
       "0                                   6279.0  ...         False         False   \n",
       "1                                   6225.0  ...         False         False   \n",
       "2                                   6121.0  ...         False         False   \n",
       "3                                   6211.0  ...         False         False   \n",
       "4                                   6172.0  ...         False         False   \n",
       "...                                    ...  ...           ...           ...   \n",
       "581007                               837.0  ...         False         False   \n",
       "581008                               845.0  ...         False         False   \n",
       "581009                               854.0  ...         False         False   \n",
       "581010                               864.0  ...         False         False   \n",
       "581011                               875.0  ...         False         False   \n",
       "\n",
       "        Soil_Type_32  Soil_Type_33  Soil_Type_34  Soil_Type_35  Soil_Type_36  \\\n",
       "0              False         False         False         False         False   \n",
       "1              False         False         False         False         False   \n",
       "2              False         False         False         False         False   \n",
       "3              False         False         False         False         False   \n",
       "4              False         False         False         False         False   \n",
       "...              ...           ...           ...           ...           ...   \n",
       "581007         False         False         False         False         False   \n",
       "581008         False         False         False         False         False   \n",
       "581009         False         False         False         False         False   \n",
       "581010         False         False         False         False         False   \n",
       "581011         False         False         False         False         False   \n",
       "\n",
       "        Soil_Type_37  Soil_Type_38  Soil_Type_39  \n",
       "0              False         False         False  \n",
       "1              False         False         False  \n",
       "2              False         False         False  \n",
       "3              False         False         False  \n",
       "4              False         False         False  \n",
       "...              ...           ...           ...  \n",
       "581007         False         False         False  \n",
       "581008         False         False         False  \n",
       "581009         False         False         False  \n",
       "581010         False         False         False  \n",
       "581011         False         False         False  \n",
       "\n",
       "[581012 rows x 54 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_ = [x for x,y in get_CoverType()]\n",
    "_ = pd.DataFrame.from_records(_)\n",
    "_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from streams.utils import FL, FU, generate_stream_section\n",
    "from streams.stream_section import StreamSection\n",
    "from river import metrics\n",
    "from multiprocessing.pool import ThreadPool\n",
    "from constants import NUMBER_OF_THREADS\n",
    "import numpy as np\n",
    "import logging\n",
    "import datetime\n",
    "\n",
    "def get_most_frequent(predictions):\n",
    "    ''' \n",
    "    Get the most common predction\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    predictions: list\n",
    "        The list of predicted labels\n",
    "\n",
    "    Returns\n",
    "    ---------\n",
    "    int\n",
    "        The most popular class\n",
    "\n",
    "    '''\n",
    "    return max(set(predictions), key=predictions.count)\n",
    "\n",
    "\n",
    "def update_performance_measures(predictions, true_label, B, metrics):\n",
    "    ''' \n",
    "    The prediction for each awaiting (for a label) instance is made every K iterations \n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    predictions: dict\n",
    "        The dictionary of predctions \n",
    "\n",
    "    true_label: int\n",
    "        The true class of an instance\n",
    "\n",
    "    B: int\n",
    "        Number of bins #TODO add somewhere the describtion\n",
    "\n",
    "    metrics: dict\n",
    "        The dictionary holding the metrics to calculate the results\n",
    "    '''\n",
    "    interval = (len(predictions)-1)/B\n",
    "    preds = list(predictions.values())\n",
    "    for b in range(B+2):\n",
    "        if b == 0:\n",
    "            metrics[b].update(true_label, preds[0])\n",
    "        elif b == B+1:\n",
    "            metrics[b].update(true_label, preds[-1])\n",
    "        if preds[int(1+interval*(b-1)):int((1+interval*b))]: #interval not empty\n",
    "                y_pred = get_most_frequent(\n",
    "                    preds[int(1+interval*(b-1)):int((1+interval*b))])\n",
    "                metrics[b].update(true_label, y_pred)\n",
    "\n",
    "\n",
    "def make_prediction_for_awaiting(h, cur_idx, P, L, K):\n",
    "    ''' \n",
    "    The prediction for each awaiting (for a label) instance is made every K iterations \n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    h: classifier\n",
    "        The trained classifer that predicts the class\n",
    "\n",
    "    cur_idx: int\n",
    "        The index of a currently processed observation\n",
    "\n",
    "    P: dict\n",
    "        The dictionary with predictions \n",
    "\n",
    "    L: dict\n",
    "        The dictionary with awaiting results\n",
    "\n",
    "    K: int\n",
    "        The number indicates how often the predction is made\n",
    "\n",
    "    '''\n",
    "    # foreach instance in L add predictionin time cur_idx in P\n",
    "    for idx, instance in L.items():\n",
    "        # make prediction every K instances\n",
    "        if abs(idx-cur_idx) % K == 0:\n",
    "            P[idx][cur_idx] = h.predict_one(instance)\n",
    "\n",
    "\n",
    "def add_delay_constant(stream, delay, no_delete_period, dataset_name, q):\n",
    "    new_stream = []\n",
    "    i = 0\n",
    "    for idx_1, idx_2, x, y, in stream:\n",
    "        if i < no_delete_period:\n",
    "            new_stream.append((i, i, x, y))\n",
    "            i = i+1\n",
    "            continue\n",
    "        if (i-no_delete_period) % delay == 0 and i-no_delete_period != 0:\n",
    "            i += delay\n",
    "        new_stream.append((i, i, x, None))\n",
    "        new_stream.append((i+delay, i, x, y))\n",
    "        i += 1\n",
    "    new_stream.sort(key=lambda x: x[0])\n",
    "    return StreamSection(f'{dataset_name}_delay_{q[0]}_{q[1]}', new_stream, False)\n",
    "\n",
    "def add_delay_random(stream, delay, no_delete_period, dataset_name, q):\n",
    "    new_stream = []\n",
    "    used_indexes = []\n",
    "    i = 0\n",
    "    for idx_1, idx_2, x, y, in stream:\n",
    "        if i < no_delete_period:\n",
    "            new_stream.append((i, i, x, y))\n",
    "            i = i+1\n",
    "            continue\n",
    "        while i in used_indexes:\n",
    "            i+=1\n",
    "        delay = np.random.randint(1,20)\n",
    "        while i+delay in used_indexes:\n",
    "            delay+=1 # if sampling again infinite loop possible\n",
    "        new_stream.append((i, i, x, None))\n",
    "        new_stream.append((i+delay, i, x, y))\n",
    "        used_indexes.extend([i,i+delay])\n",
    "        i += 1\n",
    "    new_stream.sort(key=lambda x: x[0])\n",
    "    return StreamSection(f'{dataset_name}_delay_{q[0]}_{q[1]}', new_stream, False)\n",
    "\n",
    "\n",
    "\n",
    "def train_for_stream( my_stream,methods, methods_params,methods_name,\n",
    "                       metric_fun, K, B,warm_up_period):\n",
    "    results = {}\n",
    "    # how many labelled instances appered -> needed for prediction of awaiting examples \n",
    "    labelled_insances_cnt = 0\n",
    "    logging.debug(f\" Start processing {my_stream.__name__}\")\n",
    "    for mi, method in enumerate(methods):\n",
    "            # initilaze method and variables\n",
    "        m = method(**methods_params[mi])\n",
    "        metrics = [metric_fun() for _ in range(B+2)]\n",
    "        h = m\n",
    "        L = {}\n",
    "        P = {}\n",
    "        logging.debug(f\" Start processing method {methods_name[mi]}\")\n",
    "        for cur_idx, init_idx, x, y in my_stream.stream:\n",
    "            # TODO: can it be in this place\n",
    "           \n",
    "            # unlabelled instance\n",
    "            if y is None:\n",
    "                # add instnace and index\n",
    "                L[cur_idx] = x\n",
    "                P[cur_idx] = {}\n",
    "                P[cur_idx][cur_idx] = h.predict_one(x)\n",
    "                # TODO: think what to do if the method cannot deal with unlabelled\n",
    "                h = h.learn_one(x)\n",
    "\n",
    "            # labelled instance\n",
    "            else:\n",
    "                labelled_insances_cnt+=1\n",
    "                if cur_idx != init_idx and init_idx in P.keys():  # delayed label\n",
    "                    P[init_idx][cur_idx] = h.predict_one(x)\n",
    "                    L.pop(init_idx)\n",
    "\n",
    "                    update_performance_measures(\n",
    "                        P[init_idx], y, B, metrics)\n",
    "                # TODO: probably need to implment a better option of evaluation-> for now test then train is used\n",
    "                else: #TODO: dopytac sie czy tojest ok \n",
    "                    if m._timestamp > warm_up_period:  # if in warmup period the prediction cannot be made\n",
    "                        # if it was not delayed only last prediction exists\n",
    "                        metrics[B+1].update(y, h.predict_one(x))\n",
    "                \n",
    "                make_prediction_for_awaiting(h, labelled_insances_cnt, P, L, K) \n",
    "                h = h.learn_one(x, y)\n",
    "        logging.info(f\"{my_stream.__name__}, {methods_name[mi]}, {', '.join([str(t.get())for t in metrics])}\")        \n",
    "        results[methods_name[mi]] = metrics\n",
    "    return my_stream.__name__,results\n",
    "\n",
    "\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "from river.preprocessing import StandardScaler\n",
    "\n",
    "\n",
    "def generate_stream_section(dataset, stream_name, dataset_name, with_scaling = False, start=0, stop=1000):\n",
    "    \"\"\"\n",
    "    generates the StreamSection \n",
    "    if synth geneartor for take the stop-start instances are taken\n",
    "    if needed scaling added\n",
    "\n",
    "    \"\"\"\n",
    "    #TODO: add exception\n",
    "    # TODO: Maybe move to some globalk constants\n",
    "    if dataset_name in ['LED', 'AGRAWL', 'RandomRBF','HyperPlane']:\n",
    "        to_take = stop-start\n",
    "        if not with_scaling:\n",
    "            return StreamSection(stream_name, [(cur_idx, cur_idx, instance[0], instance[1]) for cur_idx, instance in enumerate(dataset.take(to_take))], True)\n",
    "        else:\n",
    "            scaler = StandardScaler()\n",
    "            res = []\n",
    "            for cur_index,(x,y) in enumerate(dataset.take(to_take)):\n",
    "                scaler = scaler.learn_one(x)\n",
    "                x = scaler.transform_one(x)\n",
    "                res.append((cur_index,cur_index,x,y))\n",
    "            return StreamSection(stream_name, res, True)\n",
    "    elif dataset_name in ['Airlines', 'Cover_Type', 'Electricity']:\n",
    "        # dataset pass as list\n",
    "        if not with_scaling:\n",
    "            return StreamSection(stream_name, [(cur_idx, cur_idx, instance[0], instance[1]) for cur_idx, instance in enumerate(dataset[start:stop])], True)\n",
    "        else:\n",
    "            scaler = StandardScaler()\n",
    "            res = []\n",
    "            for cur_index,(x,y) in  enumerate(dataset[start:stop]):\n",
    "                scaler = scaler.learn_one(x)\n",
    "                x = scaler.transform_one(x)\n",
    "                res.append((cur_index,cur_index,x,y))\n",
    "            return StreamSection(stream_name, res, True)\n",
    "    else:\n",
    "        to_take = stop-start\n",
    "        return StreamSection(stream_name, [(cur_idx, cur_idx, instance[0], instance[1]) for cur_idx, instance in enumerate(dataset.take(to_take))], True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_stream = generate_stream_section(cds,'initail_LED_Drift_gradual','initail_LED_Drift_gradual',start=0,stop=100000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "from multiprocessing.pool import ThreadPool\n",
    "\n",
    "from mgr.train_and_eval import add_delay_constant, add_delay_random, train_for_stream\n",
    "from constants import NUMBER_OF_THREADS\n",
    "import numpy as np\n",
    "import logging\n",
    "import datetime\n",
    "\n",
    "def generate_streams1(initial_stream, dataset_name, q, probas, delay_type, delay, warm_up_period):\n",
    "    stream_set = []  # TODO chcek where this should be placed\n",
    "\n",
    "    stream_set.append(initial_stream)\n",
    "    if delay_type == 1:\n",
    "        initial_stream = add_delay_constant(\n",
    "            initial_stream.stream, delay, warm_up_period, dataset_name, q)\n",
    "        dataset_name += '_constant_delay_initial'\n",
    "        stream_set.append(initial_stream)\n",
    "    elif delay_type == 2:\n",
    "        initial_stream = add_delay_random(\n",
    "            initial_stream.stream, delay, warm_up_period, dataset_name, q)\n",
    "        dataset_name += '_random_delay_initial'\n",
    "        stream_set.append(initial_stream)\n",
    "\n",
    "    for p in probas:\n",
    "        ssl_stream = StreamSection(f'{dataset_name}_ssl_{p}_{q[0]}_{q[1]}', FU(\n",
    "            initial_stream.stream, p, warm_up_period), False)\n",
    "        lfs_stream = StreamSection(\n",
    "            f'{dataset_name}_lfs_{p}_{q[0]}_{q[1]}', FL(ssl_stream.stream), True)\n",
    "        stream_set.append(ssl_stream)\n",
    "        stream_set.append(lfs_stream)\n",
    "    return stream_set\n",
    "\n",
    "def train_and_evaluate(initial_stream, dataset_name, Q, probas, methods, methods_params,methods_name,\n",
    "                       metric_fun, delay_type, K, B, delay,warm_up_period=10):\n",
    "    '''\n",
    "    Main evaluation and traing function\n",
    "    delay_type - 0 - NONE, 1 - equal, 2- random\n",
    "    '''\n",
    "\n",
    "    now = datetime.datetime.now()\n",
    "    date_time = now.strftime(\"%d_%m_%Y_%H_%M_%S\")\n",
    "    logging.basicConfig(filename=f'logs\\\\{date_time}.log', filemode='w', format='%(asctime)s - %(message)s',level=logging.INFO,datefmt='%d-%b-%y %H:%M:%S')\n",
    "    pool = ThreadPool(NUMBER_OF_THREADS)\n",
    "    results = {}\n",
    "    for q in Q:\n",
    "        # preparing streams part\n",
    "        stream_set = generate_streams1(\n",
    "            initial_stream, dataset_name, q, probas, delay_type, delay,warm_up_period)\n",
    "        logging.debug('TStreams generated')\n",
    "        # train and evaluation part\n",
    "        for my_stream in stream_set:\n",
    "            results_for_q = train_for_stream( my_stream,methods, methods_params, methods_name,\n",
    "                       metric_fun, K, B,warm_up_period)\n",
    "    \n",
    "            \n",
    "        results[q] = results_for_q\n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_stream = generate_stream_section(cds,'LED_Drift_gradual','LED_Drift_gradual',start=0,stop=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "led3 = get_LED(0.1,True,3)\n",
    "led5 = get_LED(0.1,True,5)\n",
    "led7 = get_LED(0.1,True,7)\n",
    "\n",
    "cds = ConceptDriftStream(ConceptDriftStream(led3,led5,position=25000,width = 5000),ConceptDriftStream(led5,led7,position=25000,width = 5000), position=50000,width=5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<streams.stream_section.StreamSection at 0x2658db5f160>"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "initial_stream"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[61], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m train_and_evaluate(initial_stream,dataset_name,Q,probas,methods,m_params,[\u001b[39m'\u001b[39;49m\u001b[39mHT\u001b[39;49m\u001b[39m'\u001b[39;49m],Accuracy,\u001b[39m2\u001b[39;49m,B\u001b[39m=\u001b[39;49m\u001b[39m50\u001b[39;49m,K\u001b[39m=\u001b[39;49m\u001b[39m10\u001b[39;49m,delay\u001b[39m=\u001b[39;49m\u001b[39m100\u001b[39;49m)\n",
      "Cell \u001b[1;32mIn[33], line 52\u001b[0m, in \u001b[0;36mtrain_and_evaluate\u001b[1;34m(initial_stream, dataset_name, Q, probas, methods, methods_params, methods_name, metric_fun, delay_type, K, B, delay, warm_up_period)\u001b[0m\n\u001b[0;32m     50\u001b[0m     \u001b[39m# train and evaluation part\u001b[39;00m\n\u001b[0;32m     51\u001b[0m     \u001b[39mfor\u001b[39;00m my_stream \u001b[39min\u001b[39;00m stream_set:\n\u001b[1;32m---> 52\u001b[0m         results_for_q \u001b[39m=\u001b[39m train_for_stream( my_stream,methods, methods_params, methods_name,\n\u001b[0;32m     53\u001b[0m                    metric_fun, K, B,warm_up_period)\n\u001b[0;32m     56\u001b[0m     results[q] \u001b[39m=\u001b[39m results_for_q\n\u001b[0;32m     57\u001b[0m \u001b[39mreturn\u001b[39;00m results\n",
      "File \u001b[1;32mc:\\Users\\gosia\\Desktop\\studia\\magisterka\\env\\mgr\\train_and_eval.py:193\u001b[0m, in \u001b[0;36mtrain_for_stream\u001b[1;34m(my_stream, methods, methods_params, methods_name, metric_fun, K, B, warm_up_period)\u001b[0m\n\u001b[0;32m    190\u001b[0m                 metrics[B\u001b[39m+\u001b[39m\u001b[39m1\u001b[39m]\u001b[39m.\u001b[39mupdate(y, h\u001b[39m.\u001b[39mpredict_one(x))\n\u001b[0;32m    192\u001b[0m         make_prediction_for_awaiting(h, labelled_insances_cnt, P, L, K) \n\u001b[1;32m--> 193\u001b[0m         h \u001b[39m=\u001b[39m h\u001b[39m.\u001b[39;49mlearn_one(x, y)\n\u001b[0;32m    194\u001b[0m logging\u001b[39m.\u001b[39minfo(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mmy_stream\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m, \u001b[39m\u001b[39m{\u001b[39;00mmethods_name[mi]\u001b[39m}\u001b[39;00m\u001b[39m, \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m, \u001b[39m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mjoin([\u001b[39mstr\u001b[39m(t\u001b[39m.\u001b[39mget())\u001b[39mfor\u001b[39;00m\u001b[39m \u001b[39mt\u001b[39m \u001b[39m\u001b[39min\u001b[39;00m\u001b[39m \u001b[39mmetrics])\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)        \n\u001b[0;32m    195\u001b[0m results[methods_name[mi]] \u001b[39m=\u001b[39m metrics\n",
      "File \u001b[1;32mc:\\Users\\gosia\\Desktop\\studia\\magisterka\\env\\mgr\\semisupervised_methods\\incremental_classifier.py:51\u001b[0m, in \u001b[0;36mIncrementalClassifer.learn_one\u001b[1;34m(self, x, y)\u001b[0m\n\u001b[0;32m     48\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m     49\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\n\u001b[1;32m---> 51\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mclassifier \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mclassifier\u001b[39m.\u001b[39;49mlearn_one(x\u001b[39m=\u001b[39;49mx, y\u001b[39m=\u001b[39;49my)\n\u001b[0;32m     52\u001b[0m \u001b[39m# TODO: check if needed\u001b[39;00m\n\u001b[0;32m     53\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_timestamp \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\gosia\\Desktop\\studia\\magisterka\\env\\lib\\site-packages\\river\\tree\\hoeffding_adaptive_tree_classifier.py:217\u001b[0m, in \u001b[0;36mHoeffdingAdaptiveTreeClassifier.learn_one\u001b[1;34m(self, x, y, sample_weight)\u001b[0m\n\u001b[0;32m    214\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_root \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_new_leaf()\n\u001b[0;32m    215\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_n_active_leaves \u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m--> 217\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_root\u001b[39m.\u001b[39;49mlearn_one(x, y, sample_weight\u001b[39m=\u001b[39;49msample_weight, tree\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m)\n\u001b[0;32m    219\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_train_weight_seen_by_model \u001b[39m%\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmemory_estimate_period \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m    220\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_estimate_model_size()\n",
      "File \u001b[1;32mc:\\Users\\gosia\\Desktop\\studia\\magisterka\\env\\lib\\site-packages\\river\\tree\\nodes\\hatc_nodes.py:56\u001b[0m, in \u001b[0;36mAdaLeafClassifier.learn_one\u001b[1;34m(self, x, y, sample_weight, tree, parent, parent_branch)\u001b[0m\n\u001b[0;32m     53\u001b[0m     \u001b[39mif\u001b[39;00m k \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m     54\u001b[0m         sample_weight \u001b[39m*\u001b[39m\u001b[39m=\u001b[39m k\n\u001b[1;32m---> 56\u001b[0m aux \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mprediction(x, tree\u001b[39m=\u001b[39;49mtree)\n\u001b[0;32m     57\u001b[0m y_pred \u001b[39m=\u001b[39m \u001b[39mmax\u001b[39m(aux, key\u001b[39m=\u001b[39maux\u001b[39m.\u001b[39mget) \u001b[39mif\u001b[39;00m aux \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m     59\u001b[0m detec_in \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m \u001b[39mif\u001b[39;00m y \u001b[39m==\u001b[39m y_pred \u001b[39melse\u001b[39;00m \u001b[39m1\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\gosia\\Desktop\\studia\\magisterka\\env\\lib\\site-packages\\river\\tree\\nodes\\hatc_nodes.py:106\u001b[0m, in \u001b[0;36mAdaLeafClassifier.prediction\u001b[1;34m(self, x, tree)\u001b[0m\n\u001b[0;32m    104\u001b[0m         dist \u001b[39m=\u001b[39m normalize_values_in_dict(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstats, inplace\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n\u001b[0;32m    105\u001b[0m \u001b[39melse\u001b[39;00m:  \u001b[39m# Naive Bayes Adaptive\u001b[39;00m\n\u001b[1;32m--> 106\u001b[0m     dist \u001b[39m=\u001b[39m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49mprediction(x, tree\u001b[39m=\u001b[39;49mtree)\n\u001b[0;32m    108\u001b[0m dist_sum \u001b[39m=\u001b[39m \u001b[39msum\u001b[39m(dist\u001b[39m.\u001b[39mvalues())\n\u001b[0;32m    109\u001b[0m curr_error \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_mean_error\u001b[39m.\u001b[39mget()\n",
      "File \u001b[1;32mc:\\Users\\gosia\\Desktop\\studia\\magisterka\\env\\lib\\site-packages\\river\\tree\\nodes\\htc_nodes.py:199\u001b[0m, in \u001b[0;36mLeafNaiveBayesAdaptive.prediction\u001b[1;34m(self, x, tree)\u001b[0m\n\u001b[0;32m    184\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Get the probabilities per class for a given instance.\u001b[39;00m\n\u001b[0;32m    185\u001b[0m \n\u001b[0;32m    186\u001b[0m \u001b[39mParameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    196\u001b[0m \n\u001b[0;32m    197\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    198\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mis_active() \u001b[39mand\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_nb_correct_weight \u001b[39m>\u001b[39m\u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_mc_correct_weight:\n\u001b[1;32m--> 199\u001b[0m     \u001b[39mreturn\u001b[39;00m do_naive_bayes_prediction(x, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mstats, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msplitters)\n\u001b[0;32m    200\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    201\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39m()\u001b[39m.\u001b[39mprediction(x)\n",
      "File \u001b[1;32mc:\\Users\\gosia\\Desktop\\studia\\magisterka\\env\\lib\\site-packages\\river\\tree\\utils.py:55\u001b[0m, in \u001b[0;36mdo_naive_bayes_prediction\u001b[1;34m(x, observed_class_distribution, splitters)\u001b[0m\n\u001b[0;32m     53\u001b[0m             obs \u001b[39m=\u001b[39m splitters[att_idx]\n\u001b[0;32m     54\u001b[0m             \u001b[39m# Prior plus the log likelihood\u001b[39;00m\n\u001b[1;32m---> 55\u001b[0m             tmp \u001b[39m=\u001b[39m obs\u001b[39m.\u001b[39;49mcond_proba(x[att_idx], class_index)\n\u001b[0;32m     56\u001b[0m             votes[class_index] \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m math\u001b[39m.\u001b[39mlog(tmp) \u001b[39mif\u001b[39;00m tmp \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m \u001b[39melse\u001b[39;00m \u001b[39m0.0\u001b[39m\n\u001b[0;32m     58\u001b[0m \u001b[39m# Max log-likelihood\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\gosia\\Desktop\\studia\\magisterka\\env\\lib\\site-packages\\river\\tree\\splitter\\gaussian_splitter.py:53\u001b[0m, in \u001b[0;36mGaussianSplitter.cond_proba\u001b[1;34m(self, att_val, target_val)\u001b[0m\n\u001b[0;32m     51\u001b[0m \u001b[39mif\u001b[39;00m target_val \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_att_dist_per_class:\n\u001b[0;32m     52\u001b[0m     obs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_att_dist_per_class[target_val]\n\u001b[1;32m---> 53\u001b[0m     \u001b[39mreturn\u001b[39;00m obs(att_val)\n\u001b[0;32m     54\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m     55\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39m0.0\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\gosia\\Desktop\\studia\\magisterka\\env\\lib\\site-packages\\river\\proba\\gaussian.py:72\u001b[0m, in \u001b[0;36mGaussian.__call__\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     70\u001b[0m \u001b[39mif\u001b[39;00m var:\n\u001b[0;32m     71\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m---> 72\u001b[0m         \u001b[39mreturn\u001b[39;00m math\u001b[39m.\u001b[39mexp((x \u001b[39m-\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmu) \u001b[39m*\u001b[39m\u001b[39m*\u001b[39m \u001b[39m2\u001b[39m \u001b[39m/\u001b[39m (\u001b[39m-\u001b[39m\u001b[39m2\u001b[39m \u001b[39m*\u001b[39m var)) \u001b[39m/\u001b[39m math\u001b[39m.\u001b[39msqrt(math\u001b[39m.\u001b[39mtau \u001b[39m*\u001b[39m var)\n\u001b[0;32m     73\u001b[0m     \u001b[39mexcept\u001b[39;00m \u001b[39mValueError\u001b[39;00m:\n\u001b[0;32m     74\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39m0.0\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\gosia\\Desktop\\studia\\magisterka\\env\\lib\\site-packages\\river\\proba\\gaussian.py:49\u001b[0m, in \u001b[0;36mGaussian.mu\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     45\u001b[0m \u001b[39m@property\u001b[39m\n\u001b[0;32m     46\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mn_samples\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m     47\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_var\u001b[39m.\u001b[39mmean\u001b[39m.\u001b[39mn\n\u001b[1;32m---> 49\u001b[0m \u001b[39m@property\u001b[39m\n\u001b[0;32m     50\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mmu\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m     51\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_var\u001b[39m.\u001b[39mmean\u001b[39m.\u001b[39mget()\n\u001b[0;32m     53\u001b[0m \u001b[39m@property\u001b[39m\n\u001b[0;32m     54\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39msigma\u001b[39m(\u001b[39mself\u001b[39m):\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train_and_evaluate(initial_stream,dataset_name,Q,probas,methods,m_params,['HT'],Accuracy,2,B=50,K=10,delay=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_name = 'LED_Drift_gradual'\n",
    "Q=[(0,100000)]\n",
    "probas = [0.1]\n",
    "\n",
    "HT = HoeffdingAdaptiveTreeClassifier\n",
    "incClasif = IncrementalClassifer\n",
    "m_params = [\n",
    " {'threshold':0.7,\n",
    "  'classifier':HT,\n",
    "  'params':{'grace_period':10,'max_depth':4}}]\n",
    "methods = [incClasif]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = train_and_evaluate(initial_stream,dataset_name,Q,probas,methods,m_params,['HT'],Accuracy,2,B=50,K=10,delay=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['27_03_2023_19_55_43.log',\n",
       " '27_03_2023_20_25_57.log',\n",
       " '27_03_2023_20_27_51.log',\n",
       " '27_03_2023_20_28_36.log',\n",
       " '27_03_2023_20_33_53.log',\n",
       " '27_03_2023_22_04_08.log',\n",
       " '27_03_2023_22_09_33.log',\n",
       " '27_03_2023_22_11_40.log',\n",
       " '29_03_2023_21_45_40.log',\n",
       " 'date_time.log']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir('logs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "rr = pd.read_csv('logs//29_03_2023_21_45_40.log',header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>44</th>\n",
       "      <th>45</th>\n",
       "      <th>46</th>\n",
       "      <th>47</th>\n",
       "      <th>48</th>\n",
       "      <th>49</th>\n",
       "      <th>50</th>\n",
       "      <th>51</th>\n",
       "      <th>52</th>\n",
       "      <th>53</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>29-Mar-23 22:14:54 - initail_LED_Drift_gradual</td>\n",
       "      <td>HT</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.669044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>29-Mar-23 22:18:15 - LED_Drift_gradual_random_...</td>\n",
       "      <td>HT</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.729671</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>29-Mar-23 22:31:19 - LED_Drift_gradual_delay_0...</td>\n",
       "      <td>HT</td>\n",
       "      <td>0.642454</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.642314</td>\n",
       "      <td>0.642314</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>30-Mar-23 10:35:36 - LED_Drift_gradual_random_...</td>\n",
       "      <td>HT</td>\n",
       "      <td>0.541819</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.542274</td>\n",
       "      <td>0.542274</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>30-Mar-23 17:42:37 - initail_LED_Drift_gradual</td>\n",
       "      <td>HT</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.637007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>30-Mar-23 17:42:42 - LED_Drift_gradual_delay_0...</td>\n",
       "      <td>HT</td>\n",
       "      <td>0.554545</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.554545</td>\n",
       "      <td>0.554545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>30-Mar-23 17:42:52 - LED_Drift_gradual_random_...</td>\n",
       "      <td>HT</td>\n",
       "      <td>0.506159</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.509518</td>\n",
       "      <td>0.509518</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>30-Mar-23 17:42:54 - LED_Drift_gradual_random_...</td>\n",
       "      <td>HT</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.630045</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 54 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  0    1         2    3    4   \\\n",
       "0     29-Mar-23 22:14:54 - initail_LED_Drift_gradual   HT  0.000000  0.0  0.0   \n",
       "1  29-Mar-23 22:18:15 - LED_Drift_gradual_random_...   HT  0.000000  0.0  0.0   \n",
       "2  29-Mar-23 22:31:19 - LED_Drift_gradual_delay_0...   HT  0.642454  0.0  0.0   \n",
       "3  30-Mar-23 10:35:36 - LED_Drift_gradual_random_...   HT  0.541819  0.0  0.0   \n",
       "4     30-Mar-23 17:42:37 - initail_LED_Drift_gradual   HT  0.000000  0.0  0.0   \n",
       "5  30-Mar-23 17:42:42 - LED_Drift_gradual_delay_0...   HT  0.554545  0.0  0.0   \n",
       "6  30-Mar-23 17:42:52 - LED_Drift_gradual_random_...   HT  0.506159  0.0  0.0   \n",
       "7  30-Mar-23 17:42:54 - LED_Drift_gradual_random_...   HT  0.000000  0.0  0.0   \n",
       "\n",
       "    5    6    7    8    9   ...   44   45   46   47   48   49   50   51  \\\n",
       "0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "1  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "2  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "3  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "4  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "5  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "6  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "7  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "\n",
       "         52        53  \n",
       "0  0.000000  0.669044  \n",
       "1  0.000000  0.729671  \n",
       "2  0.642314  0.642314  \n",
       "3  0.542274  0.542274  \n",
       "4  0.000000  0.637007  \n",
       "5  0.554545  0.554545  \n",
       "6  0.509518  0.509518  \n",
       "7  0.000000  0.630045  \n",
       "\n",
       "[8 rows x 54 columns]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['29-Mar-23 22:14:54 - initail_LED_Drift_gradual',\n",
       " '29-Mar-23 22:18:15 - LED_Drift_gradual_random_delay_lfs_0.1_0_100000',\n",
       " '29-Mar-23 22:31:19 - LED_Drift_gradual_delay_0_100000',\n",
       " '30-Mar-23 10:35:36 - LED_Drift_gradual_random_delay_ssl_0.1_0_100000',\n",
       " '30-Mar-23 17:42:37 - initail_LED_Drift_gradual',\n",
       " '30-Mar-23 17:42:42 - LED_Drift_gradual_delay_0_100000',\n",
       " '30-Mar-23 17:42:52 - LED_Drift_gradual_random_delay_ssl_0.1_0_100000',\n",
       " '30-Mar-23 17:42:54 - LED_Drift_gradual_random_delay_lfs_0.1_0_100000']"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(rr.loc[:,0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "magr_env",
   "language": "python",
   "name": "magr_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
