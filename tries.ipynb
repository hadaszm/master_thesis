{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5caa51de-d122-4372-9fea-1cc030f4c04a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import river\n",
    "import river.datasets as datasets\n",
    "from river import stream\n",
    "from pprint import pprint\n",
    "import os\n",
    "from scipy.io import arff\n",
    "import pandas as pd\n",
    "from river import tree\n",
    "from river import evaluate\n",
    "from river import metrics\n",
    "\n",
    "import numpy as np\n",
    "from  streams.stream_section import StreamSection\n",
    "from streams.utils import FL, FU, generate_stream_section\n",
    "from my_datasets.getting_datasets import get_LED,get_Hyperplane,get_Electricity,get_AGRAWL,get_Airlines,get_CoverType,get_RandomRBF,transform_Electricity\n",
    "from train_and_eval import train_and_evaluate\n",
    "from functools import partial\n",
    "from train_and_eval import train_and_evaluate\n",
    "from river.metrics.accuracy import Accuracy\n",
    "from river.metrics import CohenKappa\n",
    "from multiprocessing.pool import ThreadPool\n",
    "from river.datasets.synth import ConceptDriftStream\n",
    "from tqdm import tqdm\n",
    "import pickle\n",
    "\n",
    "# methods\n",
    "from river.dummy import NoChangeClassifier,PriorClassifier\n",
    "from river.cluster import CluStream\n",
    "from river.forest.adaptive_random_forest import ARFClassifier\n",
    "from river.tree.hoeffding_adaptive_tree_classifier import  HoeffdingAdaptiveTreeClassifier\n",
    "from river.neighbors import KNNClassifier as riverKNN\n",
    "from river.naive_bayes import GaussianNB\n",
    "from semisupervised_methods.clustream_and_label import CluserAndLabel\n",
    "from semisupervised_methods.incremental_classifier import IncrementalClassifer\n",
    "from semisupervised_methods.one_nearest_neighbour import oneNNClassifer\n",
    "from river.drift import ADWIN, PageHinkley\n",
    "from semisupervised_methods.ICLC import ICLC\n",
    "from river.cluster import KMeans\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "6c49e8c8",
   "metadata": {},
   "source": [
    "# Classifers\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e09441bc",
   "metadata": {},
   "source": [
    "# Notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f6b1724c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initial = generate_stream_section(get_CoverType(),'Cover_Type','Cover_Type',stop = 20000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "47c72b6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import datetime\n",
    "now = datetime.datetime.now()\n",
    "date_time = now.strftime(\"%d_%m_%Y_%H_%M_%S\")\n",
    "logging.basicConfig(filename=f'logs\\\\{date_time}.log', filemode='w',\n",
    "                    format='%(asctime)s - %(message)s', level=logging.INFO, datefmt='%d-%b-%y %H:%M:%S')\n",
    "logger = logging.getLogger()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ddf11503",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 45312/45312 [00:00<00:00, 335266.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'threshold': 0.7, 'classifier': <class 'river.naive_bayes.gaussian.GaussianNB'>, 'params': {}}][{'threshold': 0.7, 'classifier': <class 'river.naive_bayes.gaussian.GaussianNB'>, 'params': {}}]\n",
      "\n",
      "[{'threshold': 0.7, 'classifier': <class 'river.naive_bayes.gaussian.GaussianNB'>, 'params': {}}]\n",
      "[{'threshold': 0.7, 'classifier': <class 'river.naive_bayes.gaussian.GaussianNB'>, 'params': {}}]\n",
      "list index out of range 0\n",
      "[{'threshold': 0.7, 'classifier': <class 'river.naive_bayes.gaussian.GaussianNB'>, 'params': {}}]\n",
      "list index out of range 0\n",
      "[{'threshold': 0.7, 'classifier': <class 'river.naive_bayes.gaussian.GaussianNB'>, 'params': {}}]\n",
      "list index out of range 0\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 20\u001b[0m\n\u001b[0;32m     18\u001b[0m delay_type \u001b[39m=\u001b[39m\u001b[39m0\u001b[39m\n\u001b[0;32m     19\u001b[0m methods \u001b[39m=\u001b[39m [incClasif1,incClasif2]\n\u001b[1;32m---> 20\u001b[0m res \u001b[39m=\u001b[39m train_and_evaluate(initial_stream\u001b[39m=\u001b[39;49minitial_stream,  Q\u001b[39m=\u001b[39;49mQ,\n\u001b[0;32m     21\u001b[0m                          probas\u001b[39m=\u001b[39;49mprobas, methods\u001b[39m=\u001b[39;49mmethods, methods_params\u001b[39m=\u001b[39;49mm_params,\n\u001b[0;32m     22\u001b[0m                          methods_name\u001b[39m=\u001b[39;49m[\u001b[39m'\u001b[39;49m\u001b[39mNB07\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[0;32m     23\u001b[0m                          metric_fun\u001b[39m=\u001b[39;49mAccuracy, delay_type\u001b[39m=\u001b[39;49mdelay_type, B\u001b[39m=\u001b[39;49m\u001b[39m50\u001b[39;49m, K\u001b[39m=\u001b[39;49m\u001b[39m10\u001b[39;49m, delay\u001b[39m=\u001b[39;49m\u001b[39m1000\u001b[39;49m,logger \u001b[39m=\u001b[39;49m logger, warm_up_period\u001b[39m=\u001b[39;49m\u001b[39m480\u001b[39;49m)\n",
      "File \u001b[1;32mc:\\Users\\gosia\\Desktop\\studia\\magisterka\\env\\mgr\\train_and_eval.py:347\u001b[0m, in \u001b[0;36mtrain_and_evaluate\u001b[1;34m(initial_stream, Q, probas, methods, methods_params, methods_name, metric_fun, delay_type, K, B, delay, logger, warm_up_period)\u001b[0m\n\u001b[0;32m    344\u001b[0m     \u001b[39m# train and evaluation part\u001b[39;00m\n\u001b[0;32m    345\u001b[0m     max_length \u001b[39m=\u001b[39m \u001b[39mint\u001b[39m(\n\u001b[0;32m    346\u001b[0m         np\u001b[39m.\u001b[39mceil(\u001b[39mmax\u001b[39m([\u001b[39mlen\u001b[39m(st\u001b[39m.\u001b[39mstream) \u001b[39mfor\u001b[39;00m st \u001b[39min\u001b[39;00m stream_set])\u001b[39m/\u001b[39mFREQUENCY_OF_PREDICTIONS))\n\u001b[1;32m--> 347\u001b[0m     results_for_q \u001b[39m=\u001b[39m pool\u001b[39m.\u001b[39;49mmap(\u001b[39mlambda\u001b[39;49;00m my_stream: train_for_stream(my_stream, methods, methods_params, methods_name,\n\u001b[0;32m    348\u001b[0m                                                                 metric_fun, K, B, warm_up_period, max_length,logger), stream_set)\n\u001b[0;32m    350\u001b[0m     results[q] \u001b[39m=\u001b[39m results_for_q\n\u001b[0;32m    351\u001b[0m \u001b[39mreturn\u001b[39;00m results\n",
      "File \u001b[1;32mc:\\Users\\gosia\\anaconda3\\envs\\mgr2\\lib\\multiprocessing\\pool.py:364\u001b[0m, in \u001b[0;36mPool.map\u001b[1;34m(self, func, iterable, chunksize)\u001b[0m\n\u001b[0;32m    359\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mmap\u001b[39m(\u001b[39mself\u001b[39m, func, iterable, chunksize\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[0;32m    360\u001b[0m \u001b[39m    \u001b[39m\u001b[39m'''\u001b[39;00m\n\u001b[0;32m    361\u001b[0m \u001b[39m    Apply `func` to each element in `iterable`, collecting the results\u001b[39;00m\n\u001b[0;32m    362\u001b[0m \u001b[39m    in a list that is returned.\u001b[39;00m\n\u001b[0;32m    363\u001b[0m \u001b[39m    '''\u001b[39;00m\n\u001b[1;32m--> 364\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_map_async(func, iterable, mapstar, chunksize)\u001b[39m.\u001b[39;49mget()\n",
      "File \u001b[1;32mc:\\Users\\gosia\\anaconda3\\envs\\mgr2\\lib\\multiprocessing\\pool.py:771\u001b[0m, in \u001b[0;36mApplyResult.get\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    769\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_value\n\u001b[0;32m    770\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 771\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_value\n",
      "File \u001b[1;32mc:\\Users\\gosia\\anaconda3\\envs\\mgr2\\lib\\multiprocessing\\pool.py:125\u001b[0m, in \u001b[0;36mworker\u001b[1;34m(inqueue, outqueue, initializer, initargs, maxtasks, wrap_exception)\u001b[0m\n\u001b[0;32m    123\u001b[0m job, i, func, args, kwds \u001b[39m=\u001b[39m task\n\u001b[0;32m    124\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 125\u001b[0m     result \u001b[39m=\u001b[39m (\u001b[39mTrue\u001b[39;00m, func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds))\n\u001b[0;32m    126\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    127\u001b[0m     \u001b[39mif\u001b[39;00m wrap_exception \u001b[39mand\u001b[39;00m func \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m _helper_reraises_exception:\n",
      "File \u001b[1;32mc:\\Users\\gosia\\anaconda3\\envs\\mgr2\\lib\\multiprocessing\\pool.py:48\u001b[0m, in \u001b[0;36mmapstar\u001b[1;34m(args)\u001b[0m\n\u001b[0;32m     47\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mmapstar\u001b[39m(args):\n\u001b[1;32m---> 48\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mlist\u001b[39;49m(\u001b[39mmap\u001b[39;49m(\u001b[39m*\u001b[39;49margs))\n",
      "File \u001b[1;32mc:\\Users\\gosia\\Desktop\\studia\\magisterka\\env\\mgr\\train_and_eval.py:347\u001b[0m, in \u001b[0;36mtrain_and_evaluate.<locals>.<lambda>\u001b[1;34m(my_stream)\u001b[0m\n\u001b[0;32m    344\u001b[0m     \u001b[39m# train and evaluation part\u001b[39;00m\n\u001b[0;32m    345\u001b[0m     max_length \u001b[39m=\u001b[39m \u001b[39mint\u001b[39m(\n\u001b[0;32m    346\u001b[0m         np\u001b[39m.\u001b[39mceil(\u001b[39mmax\u001b[39m([\u001b[39mlen\u001b[39m(st\u001b[39m.\u001b[39mstream) \u001b[39mfor\u001b[39;00m st \u001b[39min\u001b[39;00m stream_set])\u001b[39m/\u001b[39mFREQUENCY_OF_PREDICTIONS))\n\u001b[1;32m--> 347\u001b[0m     results_for_q \u001b[39m=\u001b[39m pool\u001b[39m.\u001b[39mmap(\u001b[39mlambda\u001b[39;00m my_stream: train_for_stream(my_stream, methods, methods_params, methods_name,\n\u001b[0;32m    348\u001b[0m                                                                 metric_fun, K, B, warm_up_period, max_length,logger), stream_set)\n\u001b[0;32m    350\u001b[0m     results[q] \u001b[39m=\u001b[39m results_for_q\n\u001b[0;32m    351\u001b[0m \u001b[39mreturn\u001b[39;00m results\n",
      "File \u001b[1;32mc:\\Users\\gosia\\Desktop\\studia\\magisterka\\env\\mgr\\train_and_eval.py:273\u001b[0m, in \u001b[0;36mtrain_for_stream\u001b[1;34m(my_stream, methods, methods_params, methods_name, metric_fun, K, B, warm_up_period, max_length, logger)\u001b[0m\n\u001b[0;32m    271\u001b[0m P \u001b[39m=\u001b[39m {}\n\u001b[0;32m    272\u001b[0m \u001b[39m# preds = []\u001b[39;00m\n\u001b[1;32m--> 273\u001b[0m logger\u001b[39m.\u001b[39mdebug(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m Start processing method \u001b[39m\u001b[39m{\u001b[39;00mmethods_name[mi]\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[0;32m    274\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m    275\u001b[0m     \u001b[39mfor\u001b[39;00m cur_idx, init_idx, x, y \u001b[39min\u001b[39;00m my_stream\u001b[39m.\u001b[39mstream:\n\u001b[0;32m    276\u001b[0m         \u001b[39m# unlabelled instance\u001b[39;00m\n",
      "\u001b[1;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "# get the data stream\n",
    "electricity = get_Electricity()\n",
    "initial_stream = transform_Electricity(electricity)\n",
    "Q=[(0,20000)]\n",
    "probas = [0.1,0.2]  # probabilities of dropping the label\n",
    "HT1 = HoeffdingAdaptiveTreeClassifier\n",
    "ARF1 = ARFClassifier\n",
    "NB1= GaussianNB\n",
    "incClasif2= IncrementalClassifer\n",
    "incClasif1= IncrementalClassifer\n",
    "incClasif3= IncrementalClassifer\n",
    "m_params = [\n",
    "\n",
    "    {'threshold':0.7,\n",
    "  'classifier':NB1,\n",
    "  'params':{}}\n",
    "]\n",
    "delay_type =0\n",
    "methods = [incClasif1,incClasif2]\n",
    "res = train_and_evaluate(initial_stream=initial_stream,  Q=Q,\n",
    "                         probas=probas, methods=methods, methods_params=m_params,\n",
    "                         methods_name=['NB07'],\n",
    "                         metric_fun=Accuracy, delay_type=delay_type, B=50, K=10, delay=1000,logger = logger, warm_up_period=480)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "651773f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 45312/45312 [00:00<00:00, 499093.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Electricity_0_20000\n",
      "Electricity_0_20000_ssl_0.1_0_20000\n",
      "Electricity_0_20000_ssl_0.2_0_20000\n"
     ]
    }
   ],
   "source": [
    "# get the data stream\n",
    "electricity = get_Electricity()\n",
    "initial_stream = transform_Electricity(electricity)\n",
    "Q=[(0,20000)]\n",
    "probas = [0.1,0.2]  # probabilities of dropping the label\n",
    "clustream = CluserAndLabel\n",
    "\n",
    "m_params = [\n",
    "    {'seed':123}]\n",
    "methods = [clustream]\n",
    "delay_type = 0 # constant delay\n",
    "\n",
    "# # run the experiment \n",
    "res = train_and_evaluate(initial_stream=initial_stream,  Q=Q,\n",
    "                         probas=probas, methods=methods, methods_params=m_params,\n",
    "                         methods_name=['CluStream'],\n",
    "                         metric_fun=Accuracy, delay_type=delay_type, B=50, K=10, delay=1000,logger = logger, warm_up_period=480)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "efaa871b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 45312/45312 [00:00<00:00, 166839.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Electricity_0_20000\n",
      "Electricity_0_20000_ssl_0.1_0_20000\n",
      "Electricity_0_20000_ssl_0.2_0_20000\n"
     ]
    }
   ],
   "source": [
    "electricity = get_Electricity()\n",
    "initial_stream = transform_Electricity(electricity)\n",
    "Q=[(0,20000)]\n",
    "probas = [0.1,0.2]  # probabilities of dropping the label\n",
    "my_method = ICLC\n",
    "Cl1= KMeans\n",
    "ARF = ARFClassifier\n",
    "m_params = [\n",
    " {  'classifer':ARF,\n",
    "  'clustering_method':Cl1,\n",
    "  'clustering_params':{},\n",
    "  'classifier_params':{},\n",
    "  'drift_detector': ADWIN,\n",
    "  'nu':100}\n",
    "]\n",
    "methods = [my_method]\n",
    "delay_type = 0 # constant delay\n",
    "\n",
    "# # run the experiment \n",
    "res = train_and_evaluate(initial_stream=initial_stream,  Q=Q,\n",
    "                         probas=probas, methods=methods, methods_params=m_params,\n",
    "                         methods_name=['ICLC'],\n",
    "                         metric_fun=CohenKappa, delay_type=delay_type, B=50, K=10, delay=1000,logger = logger, warm_up_period=480)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5cdc13d",
   "metadata": {},
   "outputs": [],
   "source": [
    "electricity = get_Electricity()\n",
    "initial_stream = transform_Electricity(electricity)\n",
    "Q=[(0,20000)]\n",
    "probas = [0.1,0.2]  # probabilities of dropping the label\n",
    "my_method = ICLC\n",
    "Cl1= KMeans\n",
    "ARF = ARFClassifier\n",
    "m_params = [\n",
    " {  'classifer':ARF,\n",
    "  'clustering_method':Cl1,\n",
    "  'clustering_params':{},\n",
    "  'classifier_params':{},\n",
    "  'drift_detector': ADWIN,\n",
    "  'nu':100}\n",
    "]\n",
    "methods = [my_method]\n",
    "delay_type = 1 # constant delay\n",
    "\n",
    "# # run the experiment \n",
    "res = train_and_evaluate(initial_stream=initial_stream,  Q=Q,\n",
    "                         probas=probas, methods=methods, methods_params=m_params,\n",
    "                         methods_name=['ICLC'],\n",
    "                         metric_fun=Accuracy, delay_type=delay_type, B=50, K=10, delay=1000,logger = logger)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "daca2371",
   "metadata": {},
   "outputs": [],
   "source": [
    "logger = logging.getLogger()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e7271cc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AGRAWAL_0_20000\n",
      "AGRAWAL_0_20000_constant_delay\n",
      "AGRAWAL_0_20000_constant_delay_ssl_0.1_0_20000\n",
      "AGRAWAL_0_20000_constant_delay_ssl_0.2_0_20000\n"
     ]
    }
   ],
   "source": [
    "ag1 =  get_AGRAWL( balance_classes= True, perturbation=0.3)\n",
    "ag2 =  get_AGRAWL( balance_classes= True, perturbation=0.6)\n",
    "stream = ConceptDriftStream(ag1,ag2, position=10000,width=20000)\n",
    "initial_stream = generate_stream_section(stream,'AGRAWAL','synth',start=0,stop=20000)\n",
    "Q=[(0,len(initial_stream.stream))]\n",
    "probas = [0.1,0.2]  # probabilities of dropping the label\n",
    "dummy1 = PriorClassifier\n",
    "dummy2 = NoChangeClassifier\n",
    "incClasif2= IncrementalClassifer\n",
    "incClasif1= IncrementalClassifer\n",
    "m_params = [\n",
    "\n",
    "  {'threshold':0.7,\n",
    "  'classifier':dummy2,\n",
    "  'params':{}}\n",
    "]\n",
    "delay_type =1\n",
    "methods = [incClasif1]\n",
    "res = train_and_evaluate(initial_stream=initial_stream,  Q=Q,\n",
    "                         probas=probas, methods=methods, methods_params=m_params,\n",
    "                         methods_name=['Majority'],\n",
    "                         metric_fun=Accuracy, delay_type=delay_type, B=50, K=10, delay=1000,logger = logger)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80ee2927",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import datetime\n",
    "now = datetime.datetime.now()\n",
    "date_time = now.strftime(\"%d_%m_%Y_%H_%M_%S\")\n",
    "logging.basicConfig(filename=f'logs\\\\{date_time}.log', filemode='w',\n",
    "                    format='%(asctime)s - %(message)s', level=logging.INFO, datefmt='%d-%b-%y %H:%M:%S')\n",
    "logger = logging.getLogger()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a0cf9067",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the data stream\n",
    "led3 = get_LED(0.1,True,3)\n",
    "led5 = get_LED(0.1,True,5)\n",
    "led7 = get_LED(0.1,True,7)\n",
    "\n",
    "cds = ConceptDriftStream(ConceptDriftStream(led3,led5,position=3750,width = 3750),ConceptDriftStream(led5,led7,position=7500,width = 5000), position=7500,width=7500)\n",
    "initial_stream = generate_stream_section(cds,'LED_gradual','synth',start=0,stop=20000)\n",
    "Q=[(0,20000)]\n",
    "probas = [0.1,0.2]  # probabilities of dropping the label\n",
    "dummy1 = PriorClassifier\n",
    "dummy2 = NoChangeClassifier\n",
    "incClasif2= IncrementalClassifer\n",
    "incClasif1= IncrementalClassifer\n",
    "m_params = [\n",
    "\n",
    "  {'threshold':0.7,\n",
    "  'classifier':dummy1,\n",
    "  'params':{}},\n",
    "  {'threshold':0.7,\n",
    "  'classifier':dummy2,\n",
    "  'params':{}}\n",
    "]\n",
    "delay_type =1\n",
    "methods = [incClasif1,incClasif2]\n",
    "res = train_and_evaluate(initial_stream=initial_stream,  Q=Q,\n",
    "                         probas=probas, methods=methods, methods_params=m_params,\n",
    "                         methods_name=['Prior','Majority'],\n",
    "                         metric_fun=Accuracy, delay_type=delay_type, B=50, K=10, delay=1000,logger = logger)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "34d63f2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the data stream\n",
    "led3 = get_LED(0.1,True,3)\n",
    "led5 = get_LED(0.1,True,5)\n",
    "led7 = get_LED(0.1,True,7)\n",
    "\n",
    "st = [(cur_idx, cur_idx, instance[0], instance[1]) for cur_idx, instance in enumerate(led3.take(3750))]\n",
    "st.extend([(cur_idx, cur_idx, instance[0], instance[1]) for cur_idx, instance in enumerate(led5.take(7500))])\n",
    "st.extend([(cur_idx, cur_idx, instance[0], instance[1]) for cur_idx, instance in enumerate(led7.take(8750))])\n",
    "initial_stream = StreamSection('LED_abrupt', st, True)\n",
    "Q=[(0,20000)]\n",
    "probas = [0.1,0.2]  # probabilities of dropping the label\n",
    "dummy1 = PriorClassifier\n",
    "dummy2 = NoChangeClassifier\n",
    "incClasif2= IncrementalClassifer\n",
    "incClasif1= IncrementalClassifer\n",
    "m_params = [\n",
    "\n",
    "  {'threshold':0.7,\n",
    "  'classifier':dummy1,\n",
    "  'params':{}},\n",
    "  {'threshold':0.7,\n",
    "  'classifier':dummy2,\n",
    "  'params':{}}\n",
    "]\n",
    "delay_type =1\n",
    "methods = [incClasif1,incClasif2]\n",
    "res = train_and_evaluate(initial_stream=initial_stream,  Q=Q,\n",
    "                         probas=probas, methods=methods, methods_params=m_params,\n",
    "                         methods_name=['Prior','Majority'],\n",
    "                         metric_fun=Accuracy, delay_type=delay_type, B=50, K=10, delay=1000,logger = logger)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "049837bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the data stream\n",
    "rbf = get_RandomRBF(change_speed=0.0001, n_centroids=50)\n",
    "\n",
    "# generate stream secion from it\n",
    "initial_stream = generate_stream_section(datastream=rbf, stream_name='RBF_moderate',\n",
    "                                         dataset_type='synth', start=0, stop=2000)\n",
    "Q=[(0,20000)]\n",
    "probas = [0.1,0.2]  # probabilities of dropping the label\n",
    "dummy1 = PriorClassifier\n",
    "dummy2 = NoChangeClassifier\n",
    "incClasif2= IncrementalClassifer\n",
    "incClasif1= IncrementalClassifer\n",
    "m_params = [\n",
    "\n",
    "  {'threshold':0.7,\n",
    "  'classifier':dummy1,\n",
    "  'params':{}},\n",
    "  {'threshold':0.7,\n",
    "  'classifier':dummy2,\n",
    "  'params':{}}\n",
    "]\n",
    "delay_type =1\n",
    "methods = [incClasif1,incClasif2]\n",
    "res = train_and_evaluate(initial_stream=initial_stream,  Q=Q,\n",
    "                         probas=probas, methods=methods, methods_params=m_params,\n",
    "                         methods_name=['Prior','Majority'],\n",
    "                         metric_fun=Accuracy, delay_type=delay_type, B=50, K=10, delay=1000,logger = logger)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "85471de9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dictionary saved successfully to file\n"
     ]
    }
   ],
   "source": [
    "# save dictionary to person_data.pkl file\n",
    "with open(f'distribution\\\\CoverType_mymethod.pkl', 'wb') as fp:\n",
    "    pickle.dump(res, fp)\n",
    "    print('dictionary saved successfully to file')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e7d8282",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dictionary saved successfully to file\n"
     ]
    }
   ],
   "source": [
    "# save dictionary to person_data.pkl file\n",
    "with open(f'distribution\\\\LED_gradual1.pkl', 'wb') as fp:\n",
    "    pickle.dump(res, fp)\n",
    "    print('dictionary saved successfully to file')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "1f42674b",
   "metadata": {},
   "source": [
    "# DATASETS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3f156ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "fligths = [(dict((i,x[i]) for i in x.keys() if i!='Delay'),x['Delay']) for x,_ in stream.iter_arff('../../datasets/airlines.arff.zip', compression='infer')]\n",
    "lda = datasets.synth.LEDDrift(123,0,True,0)\n",
    "electricity = [(dict((i,x[i]) for i in x.keys() if i!='class'),x['class']=='UP') for x,_ in stream.iter_arff('../../datasets/elecNormNew.arff.zip', compression='infer')]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ETM_37",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
